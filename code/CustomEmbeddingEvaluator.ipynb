{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YIyIe-_ZMeth",
        "ZvwJ_qfVv2Ci",
        "RdBcJxzaq_XN",
        "Nkuxi-Ubq8SP"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1mXgzO03inxD9x5qiP3WydV5GgCiaC05h",
      "authorship_tag": "ABX9TyPl/FACCruoIPaT+BajRMup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fortune-Adekogbe/VisualPlagiarism/blob/main/code/CustomEmbeddingEvaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBp6nnk6R06B",
        "outputId": "93a435ab-b5eb-441d-f304-b0c8ec1b0ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/VisualPlagiarism\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Projects/VisualPlagiarism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD_AKS9Dm9Ly",
        "outputId": "f7f91db6-2e26-4a70-e6b7-7d12d0eac63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " BLIP\t       jpeg\t   'Plagiarised images'\t\t   'Plagiarised Images UI - Sheet1.csv'\n",
            " CLIP\t       MetaCLIP    'Plagiarised images 1'\t    sigLIP\n",
            " CS_Detector   MobileCLIP  'Plagiarised Images UI.gsheet'\n"
          ]
        }
      ],
      "source": [
        "!ls data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.15.0 tensorflow==2.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QraAZTCfkfE0",
        "outputId": "eaf9ce49-71a8-4535-db5e-7b782fb3a508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.15.0\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, ml-dtypes, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.0\n",
            "    Uninstalling ml-dtypes-0.4.0:\n",
            "      Successfully uninstalled ml-dtypes-0.4.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.63 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIyIe-_ZMeth"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAowC8fTRtqc"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/CS_Detector/CLIP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtnxD2M_KhD5",
        "outputId": "1e9aebd1-47b4-40cc-dc09-dc7ffb22b696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_pairs.h5  train_pairs.h5  val_pairs.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset"
      ],
      "metadata": {
        "id": "ZvwJ_qfVv2Ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_dir = 'data/CS_Detector/CLIP'"
      ],
      "metadata": {
        "id": "t0n0rQGsv091"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "class HDF5PairDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, file_path, input1_name='image1', input2_name='image2',\n",
        "                 label_name='label', batch_size=32, emb_size=768, shuffle=True):\n",
        "        self.file_path = file_path\n",
        "        self.batch_size = batch_size\n",
        "        self.input1_name = input1_name\n",
        "        self.input2_name = input2_name\n",
        "        self.label_name = label_name\n",
        "        self.emb_size = emb_size\n",
        "        self.hf = h5py.File(self.file_path, 'r')\n",
        "        self.items = list(self.hf.keys())\n",
        "        self.num_samples = len(self.items)\n",
        "        self.indexes = np.arange(self.num_samples)\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.num_samples / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start_idx = index * self.batch_size\n",
        "        end_idx = min((index + 1) * self.batch_size, self.num_samples)\n",
        "        batch_indexes = self.indexes[start_idx:end_idx]\n",
        "\n",
        "        batch_input1 = []\n",
        "        batch_input2 = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indexes:\n",
        "            item = self.items[i]\n",
        "            group = self.hf[item]\n",
        "            image1 = np.array(group[self.input1_name])\n",
        "            image2 = np.array(group[self.input2_name])\n",
        "            label = group.attrs[self.label_name]\n",
        "\n",
        "            batch_input1.append(image1)\n",
        "            batch_input2.append(image2)\n",
        "            batch_labels.append(label)\n",
        "\n",
        "        batch_input1 = np.array(batch_input1).reshape(-1, self.emb_size)\n",
        "        batch_input2 = np.array(batch_input2).reshape(-1, self.emb_size)\n",
        "        batch_labels = np.array(batch_labels).reshape(-1, 1)\n",
        "\n",
        "        return [batch_input1, batch_input2], batch_labels\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __del__(self):\n",
        "        self.hf.close()"
      ],
      "metadata": {
        "id": "V1MlEHYl8LWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1_name = 'image1'\n",
        "input2_name = 'image2'\n",
        "label_name = 'label'\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = HDF5PairDataGenerator(\n",
        "    f\"{split_dir}/train_pairs.h5\",\n",
        "    input1_name,\n",
        "    input2_name,\n",
        "    label_name,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "validation_generator = HDF5PairDataGenerator(\n",
        "    f\"{split_dir}/val_pairs.h5\",\n",
        "    input1_name,\n",
        "    input2_name,\n",
        "    label_name,\n",
        "    batch_size\n",
        ")\n",
        "\n",
        "test_generator = HDF5PairDataGenerator(\n",
        "    f\"{split_dir}/test_pairs.h5\",\n",
        "    input1_name,\n",
        "    input2_name,\n",
        "    label_name,\n",
        "    batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "rayva0uG7keK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Dense Model"
      ],
      "metadata": {
        "id": "oPFwKqGDA4OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple model for demonstration\n",
        "input1 = keras.layers.Input(shape=(768))\n",
        "input2 = keras.layers.Input(shape=(768))\n",
        "print(input1.shape, input2.shape)\n",
        "combined = keras.layers.concatenate([input1, input2], axis=-1)\n",
        "print(combined.shape)\n",
        "dense = keras.layers.Dense(32, activation='relu')(combined)\n",
        "print(dense.shape)\n",
        "\n",
        "output = keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "print(output.shape)\n",
        "model = keras.models.Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHq0C2lE7Yle",
        "outputId": "24924e0b-8127-4029-9c08-0ae446ccea00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 768) (None, 768)\n",
            "(None, 1536)\n",
            "(None, 32)\n",
            "(None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"models/dense_768_l_.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3rci6hd9PCx",
        "outputId": "cf3c9bed-d234-4444-be79-07049deaa947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0661 - accuracy: 0.9766 - val_loss: 0.0366 - val_accuracy: 0.9889\n",
            "Epoch 2/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0248 - val_accuracy: 0.9914\n",
            "Epoch 3/10\n",
            "3762/3762 [==============================] - 144s 38ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0217 - val_accuracy: 0.9933\n",
            "Epoch 4/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0252 - val_accuracy: 0.9927\n",
            "Epoch 5/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0323 - val_accuracy: 0.9916\n",
            "Epoch 6/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0247 - val_accuracy: 0.9935\n",
            "Epoch 7/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0402 - val_accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0315 - val_accuracy: 0.9930\n",
            "Epoch 9/10\n",
            "3762/3762 [==============================] - 142s 38ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0261 - val_accuracy: 0.9940\n",
            "Epoch 10/10\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0277 - val_accuracy: 0.9935\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f218c22bd60>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"models\", exist_ok=True)\n",
        "model.save(\"models/dense_768_0.99.keras\")"
      ],
      "metadata": {
        "id": "ojPoHmD4FMMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "RdBcJxzaq_XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "\n",
        "embedding_size = 768\n",
        "\n",
        "# Input layers\n",
        "input1 = Input(shape=(embedding_size))\n",
        "input2 = Input(shape=(embedding_size))\n",
        "\n",
        "# Shared layers\n",
        "shared_dense1 = Dense(64, activation='relu')\n",
        "encoded1 = shared_dense1(input1)\n",
        "encoded2 = shared_dense1(input2)\n",
        "\n",
        "# Concatenate\n",
        "merged = concatenate([encoded1, encoded2], axis=-1)\n",
        "\n",
        "# Similarity calculation layers\n",
        "dense1 = Dense(32, activation='relu')(merged)\n",
        "output = Dense(1, activation='sigmoid')(dense1)\n",
        "print(output.shape)\n",
        "# Model\n",
        "model = Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JAfWdShgrApa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be40275-fe12-4f96-fcb8-525b20b20cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"models/dense_768_1shared_l_.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "# Training\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQdeXDLBMQBm",
        "outputId": "83a45a8a-b983-4927-8fb2-53d7842171e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "3762/3762 [==============================] - 143s 38ms/step - loss: 0.0688 - accuracy: 0.9747 - val_loss: 0.0318 - val_accuracy: 0.9901\n",
            "Epoch 2/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.0314 - val_accuracy: 0.9903\n",
            "Epoch 3/30\n",
            "3762/3762 [==============================] - 118s 31ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0228 - val_accuracy: 0.9937\n",
            "Epoch 4/30\n",
            "3762/3762 [==============================] - 118s 31ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0291 - val_accuracy: 0.9926\n",
            "Epoch 5/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0247 - val_accuracy: 0.9929\n",
            "Epoch 6/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0207 - val_accuracy: 0.9941\n",
            "Epoch 7/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0233 - val_accuracy: 0.9941\n",
            "Epoch 8/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0213 - val_accuracy: 0.9955\n",
            "Epoch 9/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0255 - val_accuracy: 0.9939\n",
            "Epoch 10/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0261 - val_accuracy: 0.9941\n",
            "Epoch 11/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0263 - val_accuracy: 0.9949\n",
            "Epoch 12/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0259 - val_accuracy: 0.9948\n",
            "Epoch 13/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0299 - val_accuracy: 0.9941\n",
            "Epoch 14/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0314 - val_accuracy: 0.9946\n",
            "Epoch 15/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0271 - val_accuracy: 0.9951\n",
            "Epoch 16/30\n",
            "3762/3762 [==============================] - 122s 32ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0297 - val_accuracy: 0.9953\n",
            "Epoch 17/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0296 - val_accuracy: 0.9950\n",
            "Epoch 18/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0276 - val_accuracy: 0.9950\n",
            "Epoch 19/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0273 - val_accuracy: 0.9951\n",
            "Epoch 20/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0433 - val_accuracy: 0.9939\n",
            "Epoch 21/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0290 - val_accuracy: 0.9953\n",
            "Epoch 22/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0407 - val_accuracy: 0.9941\n",
            "Epoch 23/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0277 - val_accuracy: 0.9954\n",
            "Epoch 24/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0370 - val_accuracy: 0.9954\n",
            "Epoch 25/30\n",
            "3762/3762 [==============================] - 122s 32ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0331 - val_accuracy: 0.9953\n",
            "Epoch 26/30\n",
            "3762/3762 [==============================] - 119s 32ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0360 - val_accuracy: 0.9950\n",
            "Epoch 27/30\n",
            "3762/3762 [==============================] - 120s 32ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0337 - val_accuracy: 0.9957\n",
            "Epoch 28/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0383 - val_accuracy: 0.9952\n",
            "Epoch 29/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0363 - val_accuracy: 0.9957\n",
            "Epoch 30/30\n",
            "3762/3762 [==============================] - 121s 32ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0372 - val_accuracy: 0.9953\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78d7681e4880>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U29pIcLsuSHg",
        "outputId": "26b100ef-f01b-47f7-a562-3c1bbb33f47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1d_768_2shared_0.9857.keras  dense_768_1shared_0.65.keras\t dense_768_l_.keras\n",
            "dense_768_0.99.keras\t\t dense_768_1shared_0.9953.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('models/dense_768_l_.keras')"
      ],
      "metadata": {
        "id": "QHiR2KtUt6m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQiTLoShGOUv",
        "outputId": "46569b8d-f909-47e0-d5fb-deae79b7c96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1265/1265 [==============================] - 34s 27ms/step - loss: 0.0208 - accuracy: 0.9950\n",
            "Test Loss: 0.020800188183784485, Test Accuracy: 0.9949575066566467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "Nkuxi-Ubq8SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "WwFbS73QrRuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define shared convolutional layers\n",
        "def build_shared_conv_layers():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "        keras.layers.MaxPooling1D(pool_size=2),\n",
        "        # keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "        # keras.layers.MaxPooling1D(pool_size=2),\n",
        "        keras.layers.Flatten()\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define input tensors\n",
        "input1 = keras.layers.Input(shape=(768,1))\n",
        "input2 = keras.layers.Input(shape=(768,1))\n",
        "\n",
        "# input1 = input1[:,...]\n",
        "# print(input1.shape)\n",
        "# input2 = input2[:,...]\n",
        "\n",
        "# Build shared convolutional layers\n",
        "shared_conv = build_shared_conv_layers()\n",
        "\n",
        "# Apply shared layers to both inputs\n",
        "conv1 = shared_conv(input1)\n",
        "conv2 = shared_conv(input2)\n",
        "\n",
        "# Concatenate the feature maps\n",
        "combined = keras.layers.concatenate([conv1, conv2], axis=-1)\n",
        "\n",
        "# Fully connected layers\n",
        "dense = keras.layers.Dense(256, activation='relu')(combined)\n",
        "# dense = keras.layers.BatchNormalization()(dense)\n",
        "# dense = keras.layers.Dropout(0.5)(dense)\n",
        "\n",
        "dense = keras.layers.Dense(128, activation='relu')(dense)\n",
        "# dense = keras.layers.BatchNormalization()(dense)\n",
        "# dense = keras.layers.Dropout(0.5)(dense)\n",
        "\n",
        "output = keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model = keras.models.Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.9))\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dLnaQD9RKkjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbJIFDgWUTqY",
        "outputId": "7a3cb0b2-f6b3-4287-edc4-2baf6855a43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3762/3762 [==============================] - 137s 36ms/step - loss: 0.1897 - accuracy: 0.9184 - val_loss: 0.0871 - val_accuracy: 0.9653\n",
            "Epoch 2/10\n",
            "3762/3762 [==============================] - 136s 36ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0562 - val_accuracy: 0.9818\n",
            "Epoch 3/10\n",
            "3762/3762 [==============================] - 136s 36ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0327 - val_accuracy: 0.9899\n",
            "Epoch 4/10\n",
            "3762/3762 [==============================] - 138s 37ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.0509 - val_accuracy: 0.9858\n",
            "Epoch 5/10\n",
            "3762/3762 [==============================] - 138s 37ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0396 - val_accuracy: 0.9903\n",
            "Epoch 6/10\n",
            "3762/3762 [==============================] - 138s 37ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0335 - val_accuracy: 0.9914\n",
            "Epoch 7/10\n",
            "3762/3762 [==============================] - 138s 37ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0423 - val_accuracy: 0.9896\n",
            "Epoch 8/10\n",
            "3762/3762 [==============================] - 138s 37ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0608 - val_accuracy: 0.9872\n",
            "Epoch 9/10\n",
            "3762/3762 [==============================] - 138s 37ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0393 - val_accuracy: 0.9898\n",
            "Epoch 10/10\n",
            "3762/3762 [==============================] - 137s 36ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0645 - val_accuracy: 0.9869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab25b4b0850>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13580804-04ce-43fc-d1bb-79c05048e8a7",
        "id": "CcTziEthUYHY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1265/1265 [==============================] - 35s 28ms/step - loss: 0.0764 - accuracy: 0.9857\n",
            "Test Loss: 0.0763879045844078, Test Accuracy: 0.9857128858566284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"models\", exist_ok=True)\n",
        "model.save(\"models/conv1d_768_2shared_0.9857.keras\")"
      ],
      "metadata": {
        "id": "aNuFrffXUYHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "oZZ1TBU5UF5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pneHKWpMTuTA",
        "outputId": "96c5cf32-ce1a-4e0f-9207-cd5f61cb48b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1d_768_2shared_0.9857.keras  dense_768_1shared_0.9953_0.0248.keras\tdense_768_l_0.0235.keras\n",
            "dense_768_0.99_l_0.0247.keras\t dense_768_1shared_l_0.0208.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "model = keras.models.load_model(\"models/dense_768_l_0.0235.keras\")"
      ],
      "metadata": {
        "id": "ryb2YOJ9b-rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ynDywvcJGt",
        "outputId": "3466165f-f475-41f4-90f6-b2cd3c2b3f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1265/1265 [==============================] - 36s 28ms/step - loss: 0.0235 - accuracy: 0.9940\n",
            "Test Loss: 0.023502349853515625, Test Accuracy: 0.9940181970596313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "eval_embeddings = \"data/CLIP/eval_embeddings.json\"\n",
        "\n",
        "with open(eval_embeddings, 'r') as fp:\n",
        "    embeddings = json.load(fp)"
      ],
      "metadata": {
        "id": "QE0_F8RcUHtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_df = pd.DataFrame(embeddings)\n",
        "embedding_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P9os3OUO8JWO",
        "outputId": "f28a966d-23f0-4e88-8090-d2ea05214018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               IMAGE  SPLIT  \\\n",
              "0  WhatsApp Image 2024-06-10 at 17.38.35_15ecdfe8...      1   \n",
              "1  WhatsApp Image 2024-06-10 at 17.38.35_15ecdfe8...      2   \n",
              "2  WhatsApp Image 2024-06-10 at 17.38.35_15ecdfe8...      3   \n",
              "3                            IMG-20240613-WA0039.jpg      1   \n",
              "4                            IMG-20240613-WA0039.jpg      2   \n",
              "\n",
              "                                      CLIP EMBEDDING  \n",
              "0  [[0.3953934908, -0.3986973464, -1.1613459587, ...  \n",
              "1  [[0.4288555384, -0.3180504143, -0.0896697417, ...  \n",
              "2  [[0.0469199754, 0.0471390374, 0.2625674009, 0....  \n",
              "3  [[0.9292801023, 0.6872065067, 0.8969425559, -0...  \n",
              "4  [[0.5844798684, 0.9285963178, 0.4280830622, 0....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b84dafc7-d864-4ac0-b658-8272d6de7ff8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IMAGE</th>\n",
              "      <th>SPLIT</th>\n",
              "      <th>CLIP EMBEDDING</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WhatsApp Image 2024-06-10 at 17.38.35_15ecdfe8...</td>\n",
              "      <td>1</td>\n",
              "      <td>[[0.3953934908, -0.3986973464, -1.1613459587, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WhatsApp Image 2024-06-10 at 17.38.35_15ecdfe8...</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.4288555384, -0.3180504143, -0.0896697417, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WhatsApp Image 2024-06-10 at 17.38.35_15ecdfe8...</td>\n",
              "      <td>3</td>\n",
              "      <td>[[0.0469199754, 0.0471390374, 0.2625674009, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IMG-20240613-WA0039.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>[[0.9292801023, 0.6872065067, 0.8969425559, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IMG-20240613-WA0039.jpg</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.5844798684, 0.9285963178, 0.4280830622, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b84dafc7-d864-4ac0-b658-8272d6de7ff8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b84dafc7-d864-4ac0-b658-8272d6de7ff8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b84dafc7-d864-4ac0-b658-8272d6de7ff8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ef0c50b-0e64-44bc-b40f-a548b45d8e62\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ef0c50b-0e64-44bc-b40f-a548b45d8e62')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ef0c50b-0e64-44bc-b40f-a548b45d8e62 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedding_df",
              "summary": "{\n  \"name\": \"embedding_df\",\n  \"rows\": 111,\n  \"fields\": [\n    {\n      \"column\": \"IMAGE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"IMG-20240613-WA0073.jpg\",\n          \"IMG-20240613-WA0071.jpg\",\n          \"IMG-20240613-WA0032.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPLIT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLIP EMBEDDING\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "res = defaultdict(list)\n",
        "for i in range(embedding_df.shape[0]):\n",
        "    row = embedding_df.iloc[i,:]\n",
        "    embedding = row[\"CLIP EMBEDDING\"]\n",
        "    imgs1 = np.array([embedding] * embedding_df.shape[0])\n",
        "    imgs2 = np.array([i for i in embedding_df[\"CLIP EMBEDDING\"]])\n",
        "    imgs1 = imgs1.reshape(-1, 768)\n",
        "    imgs2 = imgs2.reshape(-1, 768)\n",
        "    batch = [imgs1, imgs2]\n",
        "    y_preds = model.predict(batch, verbose=0)\n",
        "    top_5_indices = np.argsort(-y_preds.reshape((-1,)))[:15]\n",
        "    similar = embedding_df.loc[top_5_indices, 'IMAGE']\n",
        "    values = y_preds.reshape((-1,))[top_5_indices]\n",
        "    res[row[\"IMAGE\"]].extend(list(zip(similar,values)))"
      ],
      "metadata": {
        "id": "IUPpwi2v_LCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = {}\n",
        "for key,value in res.items():\n",
        "    df = pd.DataFrame(value, columns=['Image', 'Value'])\n",
        "    unique_df = df.groupby('Image')['Value'].mean().reset_index()\n",
        "    unique_df = unique_df.sort_values(by='Value', ascending=False)\n",
        "    output[key] = unique_df.values.tolist()[:3]"
      ],
      "metadata": {
        "id": "x0vnEgtGAyEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv(\"data/Plagiarised Images UI - Sheet1.csv\")"
      ],
      "metadata": {
        "id": "rtD6oZSf8K9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for img1, img2 in df[['Image 1', 'Image 2']].values:\n",
        "    candidates = {i[0] for i in output[img1]}\n",
        "    correct += img2 in candidates\n",
        "    total += 1\n",
        "\n",
        "correct, total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EUqEA_7O1j3",
        "outputId": "dd579941-9d87-40de-9660-c86e01179f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "18/21"
      ],
      "metadata": {
        "id": "hU2EByhB8yZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e48acf8-3bd8-43f0-96d0-8cb3294dcb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8571428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iCWM8ih5m5yp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}